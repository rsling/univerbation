% !Rnw root = ../nvuniverbation.Rnw
<<setupcorpus, cache=FALSE, include=FALSE, results='asis'>>=
opts_knit$set(self.contained=FALSE)
@

\section{Analysing the usage of noun-verb units}
\label{sec:corpusbasedanalysisoftheusageofnvunits}

In this section, we apply two quantitative methods to analyse the univerbation of N+V units using corpus data.
We motivate our choice of corpus and describe the sampling and annotation procedure in Section~\ref{sub:choiceofcorpussamplingandannotation}.
We perform exploratory analysis using association measures in Section~\ref{sub:results2associationastrengths} in order to gauge the individual tendencies of N+V units to incorporate and undergo univerbation in written language usage.
The tendencies calculated here will also be used as a covariate in the experiment reported in Section~\ref{sec:elicitedproductionofnounverbunitsinwrittenlanguage}.
Finally, the results of estimating the parameters of a multilevel model explaining the variation in the univerbation of N+V units are reported in Section~\ref{sub:results1multilevelmodel}.

\subsection{Choice of corpus, sampling, and annotation}
\label{sub:choiceofcorpussamplingandannotation}

As a first step, we adopted a data-driven approach in order to find close to all N+V units in contemporary written usage.
In a second step, we counted their occurrences in compound and disjunct spelling in the relevant morphosyntactic contexts enumerated in Section~\ref{sub:hypothesesfortheempiricalstudies}: fully nominalised as the heads of noun phrases, in \textit{am} progressives, as participles in analytical verb forms, and as infinitives in a range of verbal constructions.

Clearly, a large corpus with rich morphological and morphosyntactic annotations containing texts written in a broad variety of registers and styles (including ones written under low normative pressure) was required.
We chose the DECOW16B corpus \parencite{SchaeferBildhauer2012} because it fulfils all the aforementioned criteria.%
\footnote{\url{https://www.webcorpora.org}}
Much like the SketchEngine corpora \parencite{KilgarriffEa2014}, the COW corpora contain web documents from recent years.
However, the German DECOW (containing 20.5 billion tokens in 808 million sentences and 17.1 million documents) offers a much wider range of annotations compared to SketchEngine corpora, including morphological annotations and several levels of syntactic annotation (dependencies and topological parses).
For our purpose, the fully internal analysis of nominal compounds described in \textcite{SchaeferPankratz2018} was particularly of interest.
It allows for corpus searches of roots within nominal compounds.
For example, we could query compounds with a deverbal head such as \textit{Zeitnehmen} (`time taking').

The list of actually occurring N+V units was obtained by querying for compounds with a nominal non-head and a deverbal head.%
\footnote{See the scripts available under the following DOI for concrete queries and further details: \textsc{to be included in the accepted version}.}
The rationale behind this approach is that any N+V unit of interest should occur at least once in compound spelling as a fully nominalised compound.
Since this step relied on automatic annotation already available in the corpus, the results contained erroneous hits which we removed manually.
The resulting list contained \Sexpr{nrow(concordance)} N+V units.%
\footnote{Notice that three highly frequent N+V units were excluded because they could be considered outliers, as they have fully undergone lexicalisation and are vitually always used in compound spelling.
They are \textit{Teilnehmen} `to take part', \textit{Maßnehmen} `take measure', and \textit{Teilhaben} `have part' (meaning `to participate'.}

In the second step, we created lists of all relevant inflectional forms of the verb in each N+V unit and used these to query all possible compound and separate spellings (including variance in capitalisation) of each of the \Sexpr{nrow(concordance)} N+V unit types.
In total, \Sexpr{nice.int(35*nrow(concordance))} queries were executed to create the final data set used here, a number which clearly demonstrates the necessity of script-based corpus access in data-driven methods.
The queries were matched by \Sexpr{nice.int(sum(concordance$Joint))} compound spellings and \Sexpr{nice.int(sum(concordance$Separate))} separate spellings, which results in a total sample size of \Sexpr{nice.int(sum(concordance$Joint)+sum(concordance$Separate))} tokens.

For each N+V unit in the sample, the following variables were annotated automatically: (i) the verb lemma, (ii) the noun lemma, (iii) whether a linking element is used in the use as a full noun, (iv) the overall frequency in the corpus.
Additionally, we manually coded all \Sexpr{nrow(concordance)} N+V units for the relation holding between the verb and the noun.
The codes used in clear-cut cases were \textit{Argument} (\Sexpr{length(which(concordance$Relation=="Object"))} units) and \textit{Oblique} (\Sexpr{length(which(concordance$Relation=="Adjunct"))} units).
For \Sexpr{length(which(concordance$Relation=="Undetermined"))} units, both relations were conceivable, and those cases were coded as \textit{Undetermined}.
This class is illustrated by \textit{Daumenlutschen} (``thumb sucking''), which could correspond to the paraphrase either in (\ref{ex:daumenlutschen-a}) or in (\ref{ex:daumenlutschen-b}).

\begin{exe}
  \ex\begin{xlist}
    \ex\gll [den Daumen]\Sub{NP_{Acc}} lutschen \\
    the thumb suck\\\label{ex:daumenlutschen-a}
    \ex\gll [am Daumen]\Sub{PP} lutschen\\
    {on the} thumb suck\\\label{ex:daumenlutschen-b}
  \end{xlist}\label{ex:daumenlutschen}
\end{exe}

The data thus obtained were analysed in two ways.
First, we report the results of a collexeme analysis in Section~\ref{sub:results2associationastrengths}, which quantifies how strongly individual N+V units tend to be written as one word or two words.
The association strengths were used as a covariate in the analysis of the experiment reported in Section~\ref{sec:elicitedproductionofnounverbunitsinwrittenlanguage}.
Second, in Section~\ref{sub:results1multilevelmodel} we report a full statistical model of the alternation.

\subsection{Results 1: Association strengths}
\label{sub:results2associationastrengths}

In this section, we report an analysis of the item-specific affinities of N+V units towards univerbation.
The method we use is similar to collocation analysis (\citealt{Evert2008} for an overview) and stems from Collostructional Analysis \parencite{StefanowitschGries2003}.
More specifically, the method is called \textit{collexeme analysis} \parencite{StefanowitschGries2009}.%
\footnote{See also \selfcitet{SchaeferPankratz2018} and \selfcitet{Schaefer2019a} for similar uses.}

Our goal was to quantify how strongly each N+V unit tends towards univerbation vis-a-vis all other N+V units.
Thus, we need to compare the counts of cases with and without univerbation of the unit in question with the total counts for all other N+V units.
Such comparisons must be made relative to the overall number of the specific N+V unit as well as the number of all other units.
The counts needed for each N+V unit are nicely summarised in a 2$\times$2 contingency table as shown in Table~\ref{tab:associationsexplained}.

\begin{table}[!htbp]
  \begin{tabular}{lcc}
  \toprule
  & Compound spelling & Disjunct spelling \\
  \midrule
  Specific N+V unit   & $c_{11}$ & $c_{21}$ \\
  All other N+V units & $c_{21}$ & $c_{22}$ \\
  \bottomrule
  \end{tabular}
  \caption{2\CM{\times}2 contingency table as used in the calculation of the strengths of the associations of N+V units with univerbation}
  \label{tab:associationsexplained}
\end{table}

With these counts, we are able to quantify how strongly the proportion in the first row differ from those in the second row, and there is a range of statistical measures for that.
For example, one could use odds ratios or effects strengths from frequentist statistical tests.%
\footnote{p-values from frequentist statistical tests are measures of evidence, and therefore not appropriate in such situations \parencite{SchmidKuechenhoff2013,KuechenhoffSchmid2015} although they were used in early Collostructional Analysis.
However, even Collostructional Analysis is now often used with measures of effect strength \parencite{Gries2015b}.}
We chose Cramér's $v$ derived from standard $\chi^2$ scores ($v=\sqrt{\chi^2/n}$).
The $v$ measure quantifies for each individual N+V unit how strongly the counts (cells $c_{11}$ and $c_{21}$) deviate from its counts that we would expect if there were no difference between this unit and all other N+V units (cells $c_{21}$ and $c_{22}$) with respect to their tendency to univerbate.
Since Cramér's $v$ is always in the range between 0 and 1, it allows us to compare analyses where the samples differ.
In itself, $v$ does not tell us whether the deviation is negative (for a N+V unit with less than average compound spellings) or positive (for a N+V unit with more than average compound spellings).
The information about the direction of the deviation is added by multiplying $v$ with the sign of the upper left cell of the residual table of the $\chi^2$ test.
We calculated the signed $v$ for each of the $\Sexpr{length(concordance$all.assocs)}$ N+V units.
Their distribution is plotted in the form of a density estimate in Figure~\ref{fig:associationsall}.%
\footnote{As expected, it approximates a scaled symmetric $\chi^2$ distribution with $df=1$ squashed between -1 and 1.}

<<associationsall, results="asis", fig.showtext = TRUE, fig.pos="htbp", fig.height=3, fig.width=3, fig.cap=paste0("Density estimate of the distribution of the \\CM{", length(which(!is.na(concordance$all.assocs))), "} association scores (across all morphosyntactic conditions)")>>=

### Plot distributions of association measures.
density.opts <- list(lwd = 2)
par(family = "Fira Sans", mar=c(2.5, 2.5, 0.5, 2.5))

plot(density(na.omit(concordance$all.assocs)),
  axes = F, xlab = "", xlim = c(-0.15, 0.15), ylim = c(0,42),
  lwd = density.opts$lwd,
  col = "black", lty = 1,
  main = ""
  )
axis(1)
axis(2)
@

For the selection of the target stimuli used in the experiment, the these association strengths are important, because they encode the effect of the individual N+V units independently of the context.
To illustrate how the data analysis allows for a selection of N+V units based on their affinity towards univerbation, we show the top ten units with the highest negative and highest positive association in Table~\ref{tab:corpusassocslohi}.
The tables illustrate that units with the strongest tendencies against univerbation are predominantly ones with an argument relation.
The ones which most strongly favour univerbation are mostly ones with an oblique relation or an ambiguous relation.
This is in line with our argumentation from Section~\ref{sec:theoreticalbackground}.
The ten items with the least clear tendency in either direction are shown in Table~\ref{tab:corpusassoctablenull}.
They mostly come with an argument relation.

<<corpuscreatetabledata, results="asis">>=
corpus.assoc.sel <- format.assocs(df = concordance, col = 'all.assocs', show.results = "all",
                               show.cols = c("Compound", "all.assocs", "Relation"),
                               num = 10, cx = "All contexts", effect = "UNIVERBATION", freq.cutoff = 0.2)
corpus.assoc.sel$Relation <- revalue(corpus.assoc.sel$Relation, c("Undetermined"="Undet.", "Object"="Argument", "Adjunct"="Oblique"))
colnames(corpus.assoc.sel) <- c("N+V Unit", "Assoc.", "Rel.")
corpus.assoc.sel <- corpus.assoc.sel[, 1:3]
@

\begin{table}[!htbp]
  \begin{minipage}{.45\textwidth}
    \centering
    <<corpusassoctablehi, results="asis">>=
    corpus.assoc.hi <- xtable(corpus.assoc.sel[1:10,], digits = 3)
    print(corpus.assoc.hi,
          include.rownames=F,
          floating = F,
          table.placement = 'h!',
          booktabs = T,
          scalebox = 0.9,
          sanitize.text.function = function(x){x}
    )
    @
  \end{minipage}\hspace{1em}\begin{minipage}{.45\textwidth}
    \centering
    <<corpusassoctablelo, results="asis">>=
    corpus.assoc.lo <- xtable(corpus.assoc.sel[30:21,], digits = 3)
    print(corpus.assoc.lo,
          include.rownames=F,
          floating = F,
          table.placement = 'h!',
          booktabs = T,
          scalebox = 0.9,
          sanitize.text.function = function(x){x}
    )
    @
  \end{minipage}
  \caption{Top ten N+V units with a strong tendency for univerbation (left panel) and top ten N+V units with a strong tendency against univerbation (right panel)}
  \label{tab:corpusassocslohi}
\end{table}

<<corpusassoctablenull, results="asis", >>=
corpus.assoc.null <- xtable(corpus.assoc.sel[11:20,], digits = 3,
                            caption = paste0("Top ten N+V units without any tendency for or against univerbation"),
                            label = "tab:corpusassoctablenull")
# Print the table.
print(corpus.assoc.null,
      include.rownames=F,
      floating = T,
      table.placement = '!htbp',
      booktabs = T,
      scalebox = 0.9,
      sanitize.text.function = function(x){x},
)
@


Among the units with an argument relation, it is difficult to tell based on native-speaker intuition why the ones in Table~\ref{tab:corpusassoctablenull} should have no preference and the ones in Table~\ref{tab:corpusassocslohi} (right panel) should resist univerbation.
This goes to show that, while we can model the tendencies to some extent using linguistic features, there are obvious item-specific effects which should be taken seriously from a theoretical perspective (which is why Collostructional Analysis was introduced), and which must be accounted for in behavioural experiments.
We turn to such an experiment in Section~\ref{sec:elicitedproductionofnounverbunitsinwrittenlanguage}.
However, we first report a full statistical model of the influencing factors derived from the corpus data in Section~\ref{sub:results1multilevelmodel}.

\subsection{Results 2: Multilevel model}
\label{sub:results1multilevelmodel}

In this section, we present the parameter estimates (and predictions of conditional modes) for a binomial multilevel model (or generalised linear mixed model, GLMM) which models the relevant factors influencing writers' choice of the compound and the separate spelling.%
\footnote{See \selfcitet{Schaefer2020a} for an overview of the method and our philosophy in modelling.}
The results of the method used in Section~\ref{sub:results2associationastrengths} and the GLMM presented here converge.
However, the GLMM has a more standard interpretation and allows for finer-grained data analysis.
Also, it has long been accepted that combining several methods strengthens the analysis when the results converge (\egg \citealt{ArppeJaervikivi2007}).

Given the grand total of \Sexpr{nice.int(sum(concordance$Joint)+sum(concordance$Separate))} observations in the sample (see Section~\ref{sub:choiceofcorpussamplingandannotation}), we will completely refrain from an interpretation of the GLMM in terms of frequentist inferential statistics.
For samples of such magnitude in data-driven approaches, frequentist significance tests are the wrong tool.
Therefore, we provide standard likelihood ratio confidence intervals for parameter estimates and prediction intervals for conditional modes as an approximate measure quantifying the precision of the parameter estimates and predictions.
The models we specify reflect theoretically motivated decisions, and we therefore reject all types of model selection by means of step-up or step-down procedures.

As argued in Section~\ref{sec:thestatusofnounverbunitsingerman}, we expect the probability of the univerbation of N+V units to depend on the morphosyntactic context, the relation holding between the verb and the noun, the presence of absence of a linking element in the nominal compound (as a marker of a stronger lexicalisation) and on the specific N+V unit (a lexical tendency).
Accordingly, the response variable was chosen to be the proportion of compound spellings among all the spellings of the N+V unit.
In the input data provided to the estimator, the response variable was thus a vector of \Sexpr{nrow(concordance)} proportions, one for each N+V unit.%
\footnote{Binomial models can be specified in this manner \parencite[245--260]{ZuurEa2009}.
In the estimation of such models, the influence of each proportion is weighted according to the number of cases observed to calculate it.
Without the weighting, highly frequent observed proportions would have too small an influence on the estimation, and infrequent ones would have an inappropriately high influence.
In the case at hand, such a model on proportion data is also a convenient way of getting around the practical difficulties of estimating a model on the raw \Sexpr{nice.int(sum(concordance$Joint)+sum(concordance$Separate))} observations.}
We specified four regressors.
The only first-level (or observation-level) fixed effect regressor is the morphosyntactic context (a four-way categorical variable).
We decided to break down the possible morphosyntactic contexts into four types:

\vspace{\baselineskip}

\renewcommand{\theenumi}{\roman{enumi}}
\begin{enumerate}
  \item{\label{continf}  adjunct \textit{zu} infinitives (see example \ref{ex:disjunctspelling4}),}
  \item{\label{contpart} participles as complements of auxiliaries (see example \ref{ex:disjunctspelling3}),}
  \item{\label{contprog} the so-called \textit{am} progressive \roland{REFERENCE!}(see example \ref{ex:disjunctspelling5}),}
  \item{\label{contnp}   full NPs (see example \ref{ex:disjunctspelling7}).}
\end{enumerate}

\vspace{\baselineskip}

The constructions with the infinitive (\ref{continf}) and the participle (\ref{contpart}) represent two prototypically syntactic constructions as the verb from the N+V is part of a verbal syntagma.
The NP context (\ref{contnp}) is most prototypically nominal, especially since we only used NPs with a determiner.
More precisely, we only used NPs with definite determiners cliticised to a preposition (\textit{beim} `at the', \textit{zum} `to the', etc.).
This decision was made in order to allow for a comparison of these full nominalisations and the so-called \textit{am} progressive (\ref{contprog}).
The progressive is formed with the copula\slash auxiliary \textit{sein} `to be', the variant of the preposition \textit{an} with the cliticised definite article \textit{am} `at the' and the infinitive.
While it developed out of a construction with a copula and a plain NP within a PP, and it is formally identical to cases with the normal NPs in (\ref{contnp}), it is often assumed to be a verbal construction expressing progressive meaning.\roland{REFERENCE!}
Including NPs in this specific form along with this emerging progressive construction allows us to assess whether the hypothesised verbal semantics of the progressive makes the construction more verbal, leading to a weaker tendency towards univerbations compared to regular NPs.
To summarize, we expect N+V units in infinitives and participles (prototypically verbal) to have a weak tendency and N+V units in full NPs (prototypically nominal) to have a strong tendency towards univerbation in line with the argumentation from Section~\ref{sec:thestatusofnounverbunitsingerman}.
We have no prediction for the progressive as we are unsure whether it has truly developed into a verbal construction.

As there is a huge number of \Sexpr{nrow(concordance)} N+V units, the lexical indicator variable for the individual N+V unit should not be used as a fixed effect (\citealt[244--247]{GelmanHill2006}, \selfcitealt{Schaefer2020a}).
We specified a generalised linear mixed model with the N+V unit variable as a random effect.
The variables encoding the internal relation and the presence\slash absence of a linking element are nested inside the levels of the random effect, and they are therefore treated as second-level fixed effects in a multilevel model.
In R notation, the specification is shown in (\ref{eq:corpusglmmr}).%
\footnote{See Appendix~\ref{sec:specifictionofthecorpusglmm} for a precise specification in mathematical notation.}

\begin{equation}
  \mathtt{Univerbation\sim (1|NVUnit)+Context+Relation+Link} \label{eq:corpusglmmr}
\end{equation}

<<corpusglmm, results="asis", results="hide">>=

concordance.glmm$Relation <- factor(concordance.glmm$Relation, levels = c("Object", "Undetermined", "Adjunct"))
concordance.glmm$Context <- factor(concordance.glmm$Context, levels = c("Infinitive", "Participle", "NP", "Progressive"))
concordance.glmm$FullLink <- concordance.glmm$Link
concordance.glmm$Link <- concordance.glmm$Linkbinary

corpus.glmm <- glmer(cbind(Joint, Separate)~Context+Relation+Link+(1|Compound),
                     data=concordance.glmm, family=binomial,
                     na.action = na.fail, control=glmerControl(optimizer="nloptwrap2", optCtrl=list(maxfun=2e5))
                     )

corpus.fixefs <- fixef(corpus.glmm)
corpus.confints <- confint(corpus.glmm)
# corpus.confints <- cbind(corpus.fixefs, corpus.fixefs) # Fake CIs for quick recompiles.
corpus.glmm.r2 <- r.squaredGLMM(corpus.glmm)
@

<<corpusglmmreport, results="asis">>=

# Helper function.
format.ranef <- function(glmm, ranef) {
  require(lme4)
  .vcov   <- as.data.frame(VarCorr(glmm))
  list(Name = ranef, Intercept = .vcov[which(.vcov$grp == ranef), "vcov"], sd = .vcov[which(.vcov$grp == ranef), "sdcor"])
}

# Build the table.
corpus.ct <- cbind(corpus.fixefs, corpus.confints[1:7,])
colnames(corpus.ct) <- c("Estimate", "CI low", "CI high")
ranef.nv <- format.ranef(corpus.glmm, "Compound")
corpus.r2.txt <- paste0("Nakagawa \\& Schielzeth's \\CM{R^2_m=", nice.float(corpus.glmm.r2[1,1]), "} and \\CM{R^2_c=", nice.float(corpus.glmm.r2[1,2]), "}")
ranef.txt <- paste0("Random effect for N+V lemma: \\CM{Intercept=", nice.float(ranef.nv$Intercept), "}, \\CM{sd=", nice.float(ranef.nv$sd),
                    "}")
corpus.ctxt <- xtable(corpus.ct, digits = 3,
                    caption = paste0("Coefficient table for the binomial GLMM modelling the corpus data with 95\\% profile likelihood ratio confidence intervals. The horizontal line separates first-level and second-level effects. Weighting was used to account for the bias in models on proportion data. ", ranef.txt, ". The intercepts model the fixed effects Relation~=~Argument and Link~=~No. " , corpus.r2.txt),
                    label = "tab:corpusglmm")

# Experimental function to fix variable names.
lme4.pretty <- function(s) {
  s <- gsub("([a-z])([A-Z])", "\\1 = \\2", s)
  s <- gsub("Object", "Argument", s)
  gsub("Adjunct", "Oblique", s)
}

# Print the table.
print(corpus.ctxt,
      include.rownames=T,
      floating = T,
      table.placement = '!htbp',
      booktabs = T,
      scalebox = 1,
      hline.after = c(-1,1,4,7),
      sanitize.text.function = lme4.pretty
)
@

The estimated parameters of the model are given in Table~\ref{tab:corpusglmm}.
Additionally, effect plots for \textit{Context} and \textit{Relation} are given in Figure~\ref{fig:corpuseffects}.%
\footnote{Effect plots for binomial GLM(M)s \parencite{FoxWeisberg2018} plot the probability of the outcome across values of a regressor assuming default values for all other regressors.
While model coefficients in binomial (and other) models have no direct interpretation in terms of probability, effect plots allow a more intuitive interpretation in terms of changes in probability.}
As expected, the prototypically verbal contexts (infinitives and participles) are associated with a low probability of compound spelling (the infinitive is on the intercept, which is estimated at $\Sexpr{nice.float(corpus.ct["(Intercept)","Estimate"])}$, and participles have a coefficient of $\Sexpr{nice.float(corpus.ct["ContextParticiple","Estimate"])}$).
NPs and progressives as prototypically nominal contexts clearly favour compound spelling (coefficients of $\Sexpr{nice.float(corpus.ct["ContextNP","Estimate"])}$ and $\Sexpr{nice.float(corpus.ct["ContextProgressive","Estimate"])}$, respectively).
Both the coefficients and the effect plot (right panel in Figure~\ref{fig:corpuseffects}) show a low probability of compound spelling when an argument relation holds between the verb and the noun (on the intercept), and a high probability when the relation is oblique (coefficient $\Sexpr{nice.float(corpus.ct["RelationAdjunct","Estimate"])}$).
The undetermined cases are in between the two clear-cut cases (coefficient $\Sexpr{nice.float(corpus.ct["RelationUndetermined","Estimate"])}$).
The presence of a linking element in fully nominalised compounds favours compound spelling only slightly (coefficient $\Sexpr{nice.float(corpus.ct["LinkYes","Estimate"])}$).

<<corpuseffects, results="asis", fig.showtext=TRUE, fig.pos="!htbp", fig.height=4, fig.cap="Effect plots for the regressor encoding the morphosyntactic context of the N+V unit and the regressor encoding the syntactic relation within the N+V unit in the GLMM modelling the corpus data">>=
ef.context <- effect("Context", corpus.glmm, KR = T)
ef.context$variables$Context$levels <- c("Inf.", "Part.", "NP", "Prog.")
levels(ef.context$x$Context) <- c("Inf.", "NP", "Part.", "Prog.")
corpus.glmm.fx.context <- plot(ef.context,
                              rug = F,
                              colors = c("black", "black"),
                              main = "",
                              ylab = "Probability of univerbation",
                              xlab = "Context")

ef.rel <- effect("Relation", corpus.glmm, KR = T)
ef.rel$variables$Relation$levels <- c("Argument", "Undetermined", "Oblique")
levels(ef.rel$x$Relation) <- c("Oblique", "Argument", "Undetermined")
  # "Undetermined", "Argument", "Oblique") 1-3-2
  # "Undetermined", "Oblique", "Argument") 2-3-1
  # "Argument", "Undetermined", "Oblique") 3-1-2
  # "Argument", "Oblique", "Undetermined") 3-2-1
corpus.glmm.fx.relation <- plot(ef.rel,
                                rug=F, colors = c("black", "black"),
                                main="",
                                ylab="Probability of univerbation",
                                xlab="Relation"
)
grid.arrange(corpus.glmm.fx.context, corpus.glmm.fx.relation, ncol=2)
@


<<ranefplotsetnumber, results="hide">>=
ranefplot.num=20
@

Given the narrow confidence intervals and the high marginal measure of determination $R^2_m=\Sexpr{nice.float(corpus.glmm.r2[1,1])}$, we consider the hypotheses regarding fixed effects as well corroborated by the data, especially the effects of the context and the internal relation.
The differences differences between specific N+V units already shown in Section~\ref{sub:results2associationastrengths} show up in the model as the residual variance in the random effects (in the form of the conditional modes).%
\footnote{On a technical note, this is only the component of the variance which is not explained by the second-level effects.}
The conditional modes are centred around a second-level intercept of $\Sexpr{nice.float(ranef.nv$Intercept)}$ with a standard deviation of $\Sexpr{nice.float(ranef.nv$sd)}$.
The relatively high standard deviation is a sign that there is considerable variation across the individual N+V units.
Furthermore, the conditional $R^2_c$ is as high as $\Sexpr{nice.float(corpus.glmm.r2[1,2])}$.
This is commonly interpreted as saying that the fixed effects and the idiosyncratic effect of concrete N+V units almost fully explain the variance in the data.
A random selection of \Sexpr{nice.int(ranefplot.num)} conditional modes, which illustrates the relevance of lexical idiosyncrasies through obvious differences with mostly very narrow prediction intervals, is shown in Figure~\ref{fig:corpusranefs}.

<<corpusranefs, results="asis", fig.showtext=TRUE, fig.pos="!htbp", fig.cap="A random selection of conditional modes with 95\\% prediction intervals for the levels of the random effect in the GLMM modelling the corpus data">>=
set.seed(3478)
par(family = "Fira Sans")
corpus.ranef.selection <- ranef.plot(corpus.glmm, effect = "Compound", number = 20)
@

The individual N+V unit thus plays a major role in writers' tendency to univerbate N+V units, which conforms the results from Section~\ref{sub:results2associationastrengths}.
The results obtained from that method will be used to predict participants' behaviour in the controlled experiment reported in Section~\ref{sec:elicitedproductionofnounverbunitsinwrittenlanguage}.
